\chapter{Background}


\section{A Core Language}

GHC recognises three distinct stages of the compilation process. \cite{haskell_optimisations_1997}

% A latex list with frontend, middle, backend
\begin{enumerate}
  \item \textbf{Frontend}, parsing and type checking, enables to give clear errors that reference the unaltered source code.
  \item \textbf{Middle}, a number of optimisation transformations.
  \item \textbf{Backend}, generates and compiles to machine code, either via C-- or LLVM.
\end{enumerate}

The middle section is tasked with doing all the optimisation work it can, leaving only those optimisations to the backend
it can't otherwise perform. Within the middle section, the work is further split into sub-stages, where each transformation
is a separate, composable pass. An obvious benefit to this approach is that each pass can be tested independently. Moreover, because
the types are preserved throughout the middle section, it can be verified that each transformation does not violate the typesystem;
A strong bit of evidence towards the correctness of the compiler.

Regardless, the Haskell source language itself is not a good target for optimisation transformations. The source language wants
to be rich and expressive, which yields a datatype of over 100 constructors. Any transformation over such a datatype has far too
many cases to be considered practical to implement; Not to mention the myriad of bug-inducing edge cases. To overcome this issue, the
middle section first performs a desugaring pass, translating the source language into a far simpler intermediate language
called \textit{Core}. 

Core --- which is how we will refer to GHC intermediate representation going forward --- is designed to be as simple as possible
without being impractical. A testament to that property is the fact that we can fit the entire definition on the page:

\begin{listing}[H]
\begin{minted}{haskell}
data Expr
  | Var Id
  | Lit Literal
  | App Expr Expr
  | Lam Bndr Expr
  | Let Bind Expr
  | Case Expr Bndr Type [Alt]
  | Cast Expr CoercionR -- safe coercions are required for GADTs
  | Tick Tickish Expr  -- annotation that can contain some meta data
  | Type Type
  | Coercion Coercion
  
data Alt = Alt AltCon [Bndr] Expr
 
data Bind
  = NonRec Bndr Expr
  = Rec [(Bndr, Expr)]
  
-- the Id type contains information about
-- a variable, like it's name, a unique identifier
-- and analysis results
type Bndr = Id

type Program = [Bind]
\end{minted}
\label{code:core_def}
\caption{An ever so slightly simplified version of the Core Language}
\end{listing}

Writing an optimisation transformation essentially of type \hs{Program -> Program} does not now seem
as daunting given the drastically reduced number of cases to consider. 
Likewise, maintaining and debugging transformations is much less of a strenuous task.

\section{Contemporary Haskell comprehension}

\subsection{Communicating in Core}
\label{section:communicating_core}

We are not pioneers discovering the land of Core inspection. Since its inception, Core has
been used to communicate about programs and compiler interactions. Sifting through open issues on the
GHC compiler itself, one quickly comes across discussions elaborated by Core snippets. Consider issue
\href{https://gitlab.haskell.org/ghc/ghc/-/issues/22207}{\#22207} titled `\textit{bytestring Builder performance regressions after 9.2.3}' for example.
\hfill \break

\textit{While testing the performance characteristics of a bytestring patch meant to mitigate withForeignPtr-related performance regressions,
it was noticed that several of our Builder-related benchmarks have also regressed seriously for unrelated reasons.
The worst offender is byteStringHex, which on my machine runs about 10 times slower and allocates 21 times as much when using ghc-9.2.4 or ghc-9.4.2
as it did when using ghc-9.2.3. Here's a small program that can demonstrate this slowdown:}
\hfill \break

It then provides two snippets containing the final Core representation of \mono{byteStringHex} as produced by the two different GHC version.
Each of these documents are around 400 lines of un-highlighted code with all available information. And while having all available information
sounds like a good thing (and it is in a way) it poses a serious practicality issue.
Namely: it is exceedingly difficult for a human to read and comprehend a certain aspect of the AST while having to filter out another.
Not to mention, it solidifies reading Core as an activity reserved for only the most expert Haskell developers by, scaring others away with
a steep barrier to entry.

\subsection{Current tooling}

\subsubsection{GHC itself}

Core snippets of your program can easily be coerced out of GHC. The most information you can get
is the Core AST at each pass of the optimisation pipeline by using \mono{-ddump-core2core}.
To reduce the signal-to-noise ratio of Core snippets, one can use any number of suppression options.
It is common to suppress type arguments and type applications for example. These are largely
uninteresting because Core is only typed to facilitate the correctness preserving checks that \mono{core-lint} performs
and do not affect the compilation in any way.

As can be read in the GHC documentation, the following suppression flags are available to help to tame the beast.

\begin{table}[H]
  \begin{tabular}{p{0.35\linewidth}|p{0.65\linewidth}}
  \textbf{GHC flag} & \textbf{Effect on core printing} \\
  \hline
           & \\
  \mono{-dsuppress-all} & In dumps, suppress everything (except for uniques) that is suppressible.  \\
  \mono{-dsuppress-coercions} & Suppress the printing of coercions in Core dumps to make them shorter  \\
  \mono{-dsuppress-core-sizes} & Suppress the printing of core size stats per binding (since 9.4)  \\
  \mono{-dsuppress-idinfo} & Suppress extended information about identifiers where they are bound  \\
  \mono{-dsuppress-module-prefixes} & Suppress the printing of module qualification prefixes  \\
  \mono{-dsuppress-ticks} & Suppress "ticks" in the pretty-printer output.  \\
  \mono{-dsuppress-timestamps} & Suppress timestamps in dumps  \\
  \mono{-dsuppress-type-applications} & Suppress type applications  \\
  \mono{-dsuppress-type-signatures} & Suppress type signatures  \\
  \mono{-dsuppress-unfoldings} & Suppress the printing of the stable unfolding of a variable at its binding site  \\
  \mono{-dsuppress-uniques} & Suppress the printing of uniques in debug output (easier to use diff)  \\
  \mono{-dsuppress-var-kinds} & Suppress the printing of variable kinds\\
\end{tabular}
\end{table}

We can show how these suppression options greatly improve the readability of Core snippets by comparing the
desugared (unoptimized) Core of \mono{quicksort} with and without the \mono{-dsuppress-all} flags.

First the source:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
quicksort :: Ord a => [a] -> [a]
quicksort [] = []
quicksort (x:xs) = quicksort (filter (< x) xs) ++ [x] ++ quicksort (filter (>= x) xs)
\end{minted}
\label{code:quicksort_src}
\end{listing}

The desugared Core without suppression:

\begin{listing}[H]
\begin{minted}[linenos,fontsize=\footnotesize]{haskell}
-- RHS size: {terms: 55, types: 47, coercions: 0, joins: 0/10}
quicksort :: forall a. Ord a => [a] -> [a]
[LclIdX]
quicksort
  = \ (@ a_a1pH) ($dOrd_a1pJ :: Ord a_a1pH) ->
      let {
        $dOrd_a1w8 :: Ord a_a1pH
        [LclId]
        $dOrd_a1w8 = $dOrd_a1pJ } in
      let {
        $dOrd_a1w5 :: Ord a_a1pH
        [LclId]
        $dOrd_a1w5 = $dOrd_a1pJ } in
      \ (ds_d1wq :: [a_a1pH]) ->
        case ds_d1wq of wild_00 {
          [] -> ghc-prim-0.6.1:GHC.Types.[] @ a_a1pH;
          : x_a1hP xs_a1hQ ->
            letrec {
              greater_a1hS :: [a_a1pH]
              [LclId]
              greater_a1hS
                = let {
                    $dOrd_a1pQ :: Ord a_a1pH
                    [LclId]
                    $dOrd_a1pQ = $dOrd_a1pJ } in
                  letrec {
                    greater_a1pT :: [a_a1pH]
                    [LclId]
                    greater_a1pT
                      = filter
                          @ a_a1pH
                          (let {
                             ds_d1wF :: a_a1pH
                             [LclId]
                             ds_d1wF = x_a1hP } in
                           \ (ds_d1wE :: a_a1pH) -> > @ a_a1pH $dOrd_a1pQ ds_d1wE ds_d1wF)
                          xs_a1hQ; } in
                  greater_a1pT; } in
            letrec {
              lesser_a1hR :: [a_a1pH]
              [LclId]
              lesser_a1hR
                = let {
                    $dOrd_a1vV :: Ord a_a1pH
                    [LclId]
                    $dOrd_a1vV = $dOrd_a1pJ } in
                  letrec {
                    lesser_a1vY :: [a_a1pH]
                    [LclId]
                    lesser_a1vY
                      = filter
                          @ a_a1pH
                          (let {
                             ds_d1wD :: a_a1pH
                             [LclId]
                             ds_d1wD = x_a1hP } in
                           \ (ds_d1wC :: a_a1pH) -> < @ a_a1pH $dOrd_a1vV ds_d1wC ds_d1wD)
                          xs_a1hQ; } in
                  lesser_a1vY; } in
            ++
              @ a_a1pH
              (quicksort @ a_a1pH $dOrd_a1w5 lesser_a1hR)
              (++
                 @ a_a1pH
                 (GHC.Base.build
                    @ a_a1pH
                    (\ (@ a_d1wx)
                       (c_d1wy :: a_a1pH -> a_d1wx -> a_d1wx)
                       (n_d1wz :: a_d1wx) ->
                       c_d1wy x_a1hP n_d1wz))
                 (quicksort @ a_a1pH $dOrd_a1w8 greater_a1hS))
        }
\end{minted}
\label{code:quicksort_core_raw}
\end{listing}

The same desugared Core representation with the \mono{-dsuppress-all} flag:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
-- RHS size: {terms: 55, types: 47, coercions: 0, joins: 0/10}
quicksort
  = \ @ a_a1pH $dOrd_a1pJ ->
      let { $dOrd_a1w8 = $dOrd_a1pJ } in
      let { $dOrd_a1w5 = $dOrd_a1pJ } in
      \ ds_d1wq ->
        case ds_d1wq of wild_00 {
          [] -> [];
          : x_a1hP xs_a1hQ ->
            letrec {
              greater_a1hS
                = let { $dOrd_a1pQ = $dOrd_a1pJ } in
                  letrec {
                    greater_a1pT
                      = filter
                          (let { ds_d1wF = x_a1hP } in
                           \ ds_d1wE -> > $dOrd_a1pQ ds_d1wE ds_d1wF)
                          xs_a1hQ; } in
                  greater_a1pT; } in
            letrec {
              lesser_a1hR
                = let { $dOrd_a1vV = $dOrd_a1pJ } in
                  letrec {
                    lesser_a1vY
                      = filter
                          (let { ds_d1wD = x_a1hP } in
                           \ ds_d1wC -> < $dOrd_a1vV ds_d1wC ds_d1wD)
                          xs_a1hQ; } in
                  lesser_a1vY; } in
            ++
              (quicksort $dOrd_a1w5 lesser_a1hR)
              (++
                 (build (\ @ a_d1wx c_d1wy n_d1wz -> c_d1wy x_a1hP n_d1wz))
                 (quicksort $dOrd_a1w8 greater_a1hS))
        }

\end{minted}
\label{code:quicksort_core_dsuppress}
\end{listing}

\subsubsection{GHC Plugins}

GHC --- being also playground for academics and enthusiasts alike --- is extremely flexible when it comes to
altering its functionality. Using the now well established plugin interface, one is able to hook into almost
any operation of the front- and midsection of the compiler. One such place is managing the core2core passes that
will be run on the current module. This point of customization can be used to intersperse each core2core pass with an
identity transformation that smuggles away a copy of the AST in its full form.

One such existing plugin is \mono{ghc-dump} \cite{ghc_dump}. Besides extracting intermediate ASTs, it defines an
auxiliary core definition to which it provides a GHC version agnostic mapping. This has the increased benefit of 
being able to directly compare snapshots from different GHC versions; A not uncommon task as discussed in \cref{section:communicating_core}.
And while certainly being an improvement over plain text representation, we believe exploring and comparing such
dumps requires a more rich interface.
