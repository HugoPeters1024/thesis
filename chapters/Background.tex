\chapter{Background}

\section{A Core Language}

GHC recognises three distinct stages of the compilation process. \cite{haskell_optimisations_1997}

% A latex list with frontend, middle, backend
\begin{enumerate}
  \item \textbf{Frontend}, parsing and type checking, enables to give clear errors that reference the unaltered source code.
  \item \textbf{Middle}, a number of optimisation transformations.
  \item \textbf{Backend}, generates and compiles to machine code, either via C-- or LLVM.
\end{enumerate}

The middle section is tasked with doing all the optimisation work it can, leaving only those optimisations to the backend
it can't otherwise perform. Within the middle section, the work is further split into sub-stages, where each transformation
is a separate, composable pass. An obvious benefit to this approach is that each pass can be tested independently. Moreover, because
the types are preserved throughout the middle section, it can be verified that each transformation does not violate the typesystem;
A strong bit of evidence towards the correctness of the compiler.

Regardless, the Haskell source language itself is not a good target for optimisation transformations. The source language wants
to be rich and expressive, which yields a datatype of over 100 constructors. Any transformation over such a datatype has far too
many cases to be considered practical to implement; Not to mention the myriad of bug-inducing edge cases. To overcome this issue, the
middle section first performs a desugaring pass, translating the source language into a far simpler intermediate language
called \textit{Core}. 

Core --- which is how we will refer to GHC intermediate representation going forward --- is designed to be as simple as possible
without being impractical. A testament to that property is the fact that we can fit the entire definition on the page:

\begin{listing}[H]
\begin{minted}{haskell}
data Expr
  | Var Id
  | Lit Literal
  | App Expr Expr
  | Lam Bndr Expr
  | Let Bind Expr
  | Case Expr Bndr Type [Alt]
  | Cast Expr CoercionR -- safe coercions are required for GADTs
  | Tick Tickish Expr  -- annotation that can contain some meta data
  | Type Type
  | Coercion Coercion
  
data Alt = Alt AltCon [Bndr] Expr
 
data Bind
  = NonRec Bndr Expr
  = Rec [(Bndr, Expr)]
  
-- the Var type contains information about
-- a variable, like it's name, a unique identifier
-- and analysis results
type Bndr = Id
type Id = Var

type Program = [Bind]
\end{minted}
\label{code:core_def}
\caption{An ever so slightly simplified version of the Core Language}
\end{listing}

Writing an optimisation transformation essentially of type \hs{Program \rightarrow Program} does not now seem
as daunting given the drastically reduced number of cases to consider. 
Likewise, maintaining and debugging transformations is much less of a strenuous task.

\section{The core2core transformations}

Over its numerous decades of development, the core2core pipeline has been fitted with a myriad of transformations.
It would be impractical to discuss all them here. However, we will discuss in depth the role of the four 5 simplifier
passes, as well as the worker/wrapper transformation. The first because it gives context to the rewrite rules and the latter
because it is a natural bridge to unboxed types; both concepts which will become relevant in discussing the results of this thesis.

\subsection{The simplifier: its parts}

The simplifier is quite literally an indispensable part of the transformation pipeline. Although the parts of the pipeline
are meant to be seperable entities, they heavily rely on the simplifier to deal with the cleanup. As such, it has earned
itself the reputation of being the workhorse of the pipeline. \cite{ghc_wiki}

If you were looking for an atom, you have not found it. The simplifier is in itself again a collection of smaller transformations,
albeit applied concurrently. Each simplifier subpart is a local transformation, that is, it only looks at the immediate
surroundings of the expression. We give a near comprehensive list of each subpart along with an example:

\subsubsection{Constant Folding}
Evaluate expressions that require no runtime information. This is a very logical transformation that does not
require any considerations.

\begin{listing}[H]
\begin{minted}{haskell}
-- before
3 + 4
-- after
7
\end{minted}
\end{listing}

\subsubsection{Inlining-1}

Inlining function calls is a well known performance enhancing operation in all language, but especially so in functional ones.
The difference is staggering with a around 10-15\% performance increase for conventional languages, as opposed to
30-40\% for functional languages. \cite{haskell_optimisations_1997} \cite{c_inliner}.

Unlike constant folding, it is not an ad-hoc no brainer. An easy case would be to inline a function that is
used exactly once. All that this does is remove the veil that hides the function body for further optimisations:

\begin{listing}[H]
\begin{minted}{haskell}
-- before
f x = x + 1
f 3
-- after
3 + 1
\end{minted}
\end{listing}

However, if the function is used in multiple locations with different arguments, you risk increasing the size of the program
because the function body will be duplicated at each call-site. This is a trade-off that --- altough often worth it --- must be
considered on a case to case basis. GHC has a number of heuristics to determine whether inlining is worth it or not. Obviously,
this cannot be a perfect solution and one can imagine how a small change in the code can suddenly cause the inliner to reverse
its decision; a testament to the non-continuous nature of the compiler.

\subsubsection{Inlining-2}

Let bindings are often described as syntax sugar for lambda abstractions, there is an important difference to be considered.
Because let bindings in Haskell are lazily evaluated, it may lead to explosion if the let bound variable is used in a lambda
expression. For example:

\begin{listing}[H]
\begin{minted}{haskell}
-- before, 'expensive' is called at most once
let v = expensive 42
    l x = ... v ...
in map xs

-- after, 'expensive' is called for each element of 'xs'
let l x = ... expensive 42 ...
in map xs
\end{minted}
\end{listing}

This transformation would be disastrous for performance and GHC will take greate care to avoid it. 

\subsubsection{Case of known constructor}

The case destruction is only the way to get to the WHNF of an expression. This means that inside of a case expression
we have learned information about the variable under scrutiny and can use it to infer the result of outer case expressions.
Consider the following scenario:

\begin{listing}[H]
\begin{minted}{haskell}
safe_tail :: [a] -> [a]
safe_tail list = case list of
  [] -> []
  x:xs -> tail list
\end{minted}
\end{listing}

Which inlining will transform into:

\begin{listing}[H]
\begin{minted}{haskell}
safe_tail :: [a] -> [a]
safe_tail list = case list of
  [] -> []
  x:xs -> case xs of
    [] -> error "tail of empty list"
    (x:xs) -> xs
\end{minted}
\end{listing}

Since we scrutinize \mono{xs} again in the inner case, we actually already know that the second case is only ever called,
thus we can eliminate the case expression as a whole.

\begin{listing}[H]
\begin{minted}{haskell}
safe_tail :: [a] -> [a]
safe_tail list = case list of
  [] -> []
  x:xs -> xs
\end{minted}
\end{listing}

The removal of the call \mono{error} is a testament to this function being deserving of the \mono{safe} prefix.

\subsubsection{Case of case}

There are cases (no pun intended) where the case-of-know-constructor cannot quite do its job, although it is obvious
that benefits are still to be gained. Consider for example what happens when instead of scrutinizing the same variable,
the outer case scrutinizes the result of the innner case:


\begin{listing}[H]
\begin{minted}{haskell}
-- before (possibly desugared from 'if (not x) then E1 else E2'
-- after also inlining 'not')
case (case x of {True -> False; False -> True}) of
  True -> E1
  False -> E2
\end{minted}
\end{listing}

We might hope to gain something from the information that the inner case has produced by moving the outer case expression
to each branch of the inner one:

\begin{listing}[H]
\begin{minted}{haskell}
case x of
  True -> case False of {True -> E1; False -> E2}
  False -> case True of {True -> E1; False -> E2}
\end{minted}
\end{listing}

Now we can rely on constant folding to simplify all the way down to:

\begin{listing}[H]
\begin{minted}{haskell}
case x of
  True -> E2
  False -> E1
\end{minted}
\end{listing}

Note that we do risk duplicating \mono{E1} and \mono{E2} if the expression does not reduce so completely.
A solution to this are \textit{join points}, which we will not go into here for the sake of brevity.

\subsubsection{Rewrite rules}

We already discussed in \cref{section:introduction:rewrite_rules} how rewrite rules are way to express domain
specific knowledge to the compiler that it otherwise can't practically infer. Applying given rewrite rules is task
also given to the simplifier. It should now be clear that this process can get a little messy since the simplifier
is under no obligation to apply the rules, nor its other tasks, in any particular order. We will get into this issue
more in the next section where we discuss the simplifier at large.

It should be noted that the use of rewrite rules are very common during the compilation of most any haskell program.
This is because the internal fusion system on list operations are implemented as built in rewrite rules.
We discuss this system more in depth in \cref{section:background:fusion}.



\subsection{The simplifier: its sum}

An attentive reader might have noticed that when explaining one part of the simplifier, we often relied on another to
its job. This begs the question: how does the simplifier determine in which order to run its subparts. The answer to that is
that it does not. The analogy here is that a compiler is a gun and a program is a target. Every program is very different
and we cannot know in advance how to best hit it. Therefore, we must ensure that the compiler --- or this case the simplifier stage ---
has a lot of bullets in its gun to ensure being able to effectively hit a lot of targets. \cite{haskell_optimisations_1997}

A secondary problem with this approach is that one simplifier part may enable another to its job after. Running the simplifier
once is therefore not satisfactory and we must run it until it reaches a sort of \textit{fixed point}. At least up until some
arbitrary limit since there is no guarantee such a fixed point exists and even if it does that we find it and not get stuck in a loop.

Aforementioned looping beheavior can actually occur quite easily due to certain rewrite rules. It is not always the case that
the RHS of a rewrite rules objectively better than the right. It might be that the rewrite is benificial because it \textbf{may}
enable other optimisation to take place afterwards. However, if for some reason that did not turn out to be possible, we may want
to apply the reverse rewrite rule later. This is obviously problematic as we can be ping-pong between rewrite rules forever.
To overcome that issue one can enable/disable rewrites rules in certain phases of simplifier. To understand this we must first
understand when the simplifier is run.

In order, the simplifier is --- rather unituitively --- interspersed between other transformations as follows:

\begin{enumerate}
  \item \textbf{Gentle} (disables case-of-case transformations)
  \item \textbf{Phase 2}
  \item \textbf{Phase 1}
  \item \textbf{Phase 0}
  \item \textbf{Final}
\end{enumerate}

By default, rewrite rules as well as inlinings can occur in each of these phases but the programmer does have to ability
to specify devations from this beheavior. For example, in the \mono{text} library, we find in the \mono{Data.Text} module
the following snippet:

\begin{listing}[H]
\begin{minted}{haskell}
-- This function gives the same answer as comparing against the result
-- of 'length', but can short circuit if the count of characters is
-- greater than the number, and hence be more efficient.
compareLength :: Text -> Int -> Ordering
compareLength t c = S.compareLengthI (stream t) c
{-# INLINE [1] compareLength #-}

{-# RULES
"TEXT compareN/length -> compareLength" [~1] forall t n.
    compare (length t) n = compareLength t n
#-}
\end{minted}
\end{listing}

Here phase control is used to indicate that \mono{compareLength} should \textbf{only} be inlined in phase 1 and conversely
that the rewrite rule \textbf{compareN/length} maybe applied \textbf{except} in phase 1. What this ensures is that the inliner
will not operate on the result of the rewrite rule directly in the same phase. This is supposedly because we expect \mono{compareLength}
to occur in the LHS of a different rewrite rule which is to be desired over inlining at first.

\subsection{The worker/wrapper transformation}

\section{The fusion system}
\label{section:background:fusion}

build/fold using rewrite rules

\section{Contemporary Haskell comprehension}

\subsection{Communicating in Core}
\label{section:communicating_core}

We are not pioneers discovering the land of Core inspection. Since its inception, Core has
been used to communicate about programs and compiler interactions. Sifting through open issues on the
GHC compiler itself, one quickly comes across discussions elaborated by Core snippets. Consider issue
\href{https://gitlab.haskell.org/ghc/ghc/-/issues/22207}{\#22207} titled `\textit{bytestring Builder performance regressions after 9.2.3}' for example.
\hfill \break

\textit{While testing the performance characteristics of a bytestring patch meant to mitigate withForeignPtr-related performance regressions,
it was noticed that several of our Builder-related benchmarks have also regressed seriously for unrelated reasons.
The worst offender is byteStringHex, which on my machine runs about 10 times slower and allocates 21 times as much when using ghc-9.2.4 or ghc-9.4.2
as it did when using ghc-9.2.3. Here's a small program that can demonstrate this slowdown:}
\hfill \break

It then provides two snippets containing the final Core representation of \mono{byteStringHex} as produced by the two different GHC version.
Each of these documents are around 400 lines of un-highlighted code with all available information. And while having all available information
sounds like a good thing (and it is in a way) it poses a serious practicality issue.
Namely: it is exceedingly difficult for a human to read and comprehend a certain aspect of the AST while having to filter out another.
Not to mention, it solidifies reading Core as an activity reserved for only the most expert Haskell developers by, scaring others away with
a steep barrier to entry.

\subsection{Current tooling}

\subsubsection{GHC itself}


Core snippets of your program can easily be coerced out of GHC. The most information you can get
is the Core AST at each pass of the optimisation pipeline by using \mono{-ddump-core2core}.
To reduce the signal-to-noise ratio of Core snippets, one can use any number of suppression options.
It is common to suppress type arguments and type applications for example. These are largely
uninteresting because Core is only typed to facilitate the correctness preserving checks that \mono{core-lint} performs
and do not affect the compilation in any way.

As can be read in the GHC documentation, the following suppression flags are available to help to tame the beast.

\begin{table}[H]
  \begin{tabular}{p{0.35\linewidth}|p{0.65\linewidth}}
  \textbf{GHC flag} & \textbf{Effect on core printing} \\
  \hline
           & \\
  \mono{-dsuppress-all} & In dumps, suppress everything (except for uniques) that is suppressible.  \\
  \mono{-dsuppress-coercions} & Suppress the printing of coercions in Core dumps to make them shorter  \\
  \mono{-dsuppress-core-sizes} & Suppress the printing of core size stats per binding (since 9.4)  \\
  \mono{-dsuppress-idinfo} & Suppress extended information about identifiers where they are bound  \\
  \mono{-dsuppress-module-prefixes} & Suppress the printing of module qualification prefixes  \\
  \mono{-dsuppress-ticks} & Suppress "ticks" in the pretty-printer output.  \\
  \mono{-dsuppress-timestamps} & Suppress timestamps in dumps  \\
  \mono{-dsuppress-type-applications} & Suppress type applications  \\
  \mono{-dsuppress-type-signatures} & Suppress type signatures  \\
  \mono{-dsuppress-unfoldings} & Suppress the printing of the stable unfolding of a variable at its binding site  \\
  \mono{-dsuppress-uniques} & Suppress the printing of uniques in debug output (easier to use diff)  \\
  \mono{-dsuppress-var-kinds} & Suppress the printing of variable kinds\\
\end{tabular}
\end{table}

We can show how these suppression options greatly improve the readability of Core snippets by comparing the
desugared (unoptimized) Core of \mono{quicksort} with and without the \mono{-dsuppress-all} flags.

First the source:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
quicksort :: Ord a => [a] -> [a]
quicksort [] = []
quicksort (x:xs) = quicksort (filter (< x) xs) ++ [x] ++ quicksort (filter (>= x) xs)
\end{minted}
\label{code:quicksort_src}
\end{listing}

The desugared Core without suppression:

\begin{listing}[H]
\begin{minted}[linenos,fontsize=\footnotesize]{haskell}
-- RHS size: {terms: 55, types: 47, coercions: 0, joins: 0/10}
quicksort :: forall a. Ord a => [a] -> [a]
[LclIdX]
quicksort
  = \ (@ a_a1pH) ($dOrd_a1pJ :: Ord a_a1pH) ->
      let {
        $dOrd_a1w8 :: Ord a_a1pH
        [LclId]
        $dOrd_a1w8 = $dOrd_a1pJ } in
      let {
        $dOrd_a1w5 :: Ord a_a1pH
        [LclId]
        $dOrd_a1w5 = $dOrd_a1pJ } in
      \ (ds_d1wq :: [a_a1pH]) ->
        case ds_d1wq of wild_00 {
          [] -> ghc-prim-0.6.1:GHC.Types.[] @ a_a1pH;
          : x_a1hP xs_a1hQ ->
            letrec {
              greater_a1hS :: [a_a1pH]
              [LclId]
              greater_a1hS
                = let {
                    $dOrd_a1pQ :: Ord a_a1pH
                    [LclId]
                    $dOrd_a1pQ = $dOrd_a1pJ } in
                  letrec {
                    greater_a1pT :: [a_a1pH]
                    [LclId]
                    greater_a1pT
                      = filter
                          @ a_a1pH
                          (let {
                             ds_d1wF :: a_a1pH
                             [LclId]
                             ds_d1wF = x_a1hP } in
                           \ (ds_d1wE :: a_a1pH) -> > @ a_a1pH $dOrd_a1pQ ds_d1wE ds_d1wF)
                          xs_a1hQ; } in
                  greater_a1pT; } in
            letrec {
              lesser_a1hR :: [a_a1pH]
              [LclId]
              lesser_a1hR
                = let {
                    $dOrd_a1vV :: Ord a_a1pH
                    [LclId]
                    $dOrd_a1vV = $dOrd_a1pJ } in
                  letrec {
                    lesser_a1vY :: [a_a1pH]
                    [LclId]
                    lesser_a1vY
                      = filter
                          @ a_a1pH
                          (let {
                             ds_d1wD :: a_a1pH
                             [LclId]
                             ds_d1wD = x_a1hP } in
                           \ (ds_d1wC :: a_a1pH) -> < @ a_a1pH $dOrd_a1vV ds_d1wC ds_d1wD)
                          xs_a1hQ; } in
                  lesser_a1vY; } in
            ++
              @ a_a1pH
              (quicksort @ a_a1pH $dOrd_a1w5 lesser_a1hR)
              (++
                 @ a_a1pH
                 (GHC.Base.build
                    @ a_a1pH
                    (\ (@ a_d1wx)
                       (c_d1wy :: a_a1pH -> a_d1wx -> a_d1wx)
                       (n_d1wz :: a_d1wx) ->
                       c_d1wy x_a1hP n_d1wz))
                 (quicksort @ a_a1pH $dOrd_a1w8 greater_a1hS))
        }
\end{minted}
\label{code:quicksort_core_raw}
\end{listing}

The same desugared Core representation with the \mono{-dsuppress-all} flag:

\begin{listing}[H]
\begin{minted}[linenos,fontsize=\footnotesize]{haskell}
-- RHS size: {terms: 55, types: 47, coercions: 0, joins: 0/10}
quicksort
  = \ @ a_a1pH $dOrd_a1pJ ->
      let { $dOrd_a1w8 = $dOrd_a1pJ } in
      let { $dOrd_a1w5 = $dOrd_a1pJ } in
      \ ds_d1wq ->
        case ds_d1wq of wild_00 {
          [] -> [];
          : x_a1hP xs_a1hQ ->
            letrec {
              greater_a1hS
                = let { $dOrd_a1pQ = $dOrd_a1pJ } in
                  letrec {
                    greater_a1pT
                      = filter
                          (let { ds_d1wF = x_a1hP } in
                           \ ds_d1wE -> > $dOrd_a1pQ ds_d1wE ds_d1wF)
                          xs_a1hQ; } in
                  greater_a1pT; } in
            letrec {
              lesser_a1hR
                = let { $dOrd_a1vV = $dOrd_a1pJ } in
                  letrec {
                    lesser_a1vY
                      = filter
                          (let { ds_d1wD = x_a1hP } in
                           \ ds_d1wC -> < $dOrd_a1vV ds_d1wC ds_d1wD)
                          xs_a1hQ; } in
                  lesser_a1vY; } in
            ++
              (quicksort $dOrd_a1w5 lesser_a1hR)
              (++
                 (build (\ @ a_d1wx c_d1wy n_d1wz -> c_d1wy x_a1hP n_d1wz))
                 (quicksort $dOrd_a1w8 greater_a1hS))
        }

\end{minted}
\label{code:quicksort_core_dsuppress}
\end{listing}

A drastic improvement for sure, but there are still some things to be left desired.
A simpler language like Core generally needs more code to express the same thing, we can thus expect
to generate more data than the original Haskell code. Moreover, should you be interested the state off
the program at each of the intermediate steps, you can expect to see about 20x more data still.
Unless you know exactly what to search for, this begs for a more ergonomic, filtered view of the data.

\subsubsection{GHC Plugins}

GHC --- being also playground for academics and enthusiasts alike --- is extremely flexible when it comes to
altering its functionality. Using the now well established plugin interface, one is able to hook into almost
any operation of the front- and midsection of the compiler. One such place is managing the core2core passes that
will be run on the current module. This point of customization can be used to intersperse each core2core pass with an
identity transformation that smuggles away a copy of the AST in its full form.

One such existing plugin is \mono{ghc-dump} \cite{ghc_dump}. Besides extracting intermediate ASTs, it defines an
auxiliary core definition to which it provides a GHC version agnostic mapping. This has the increased benefit of 
being able to directly compare snapshots from different GHC versions; A not uncommon task as discussed in \cref{section:communicating_core}.
And while certainly being an improvement over plain text representation, we believe exploring and comparing such
dumps requires a more rich interface.
