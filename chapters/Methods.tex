\chapter{Methods}

\section{Requirements and architecture}

\begin{itemize}
  \item GHC version agnostic (to where reasonable i.e. 8.4 onwards)
  \item Simple and non invase steps to create dumps
  \item Cross-platform ability to explore dumps
  \item Not everything needs to be supported (think unfoldings) but should be extendible in the future
\end{itemize}

We envisioned a high degree of interactability with the snapshots of the intermediate ASTs. To realise this
in a cross-platform fashion, we decided to use a browser based frontend application. Because the concept of
mutually recursive algebraic datatypes are very pervasive in the Core AST, we felt it would be helpful
if the frontend language had first class support for this. This naturally led to us to Elm, a functional language
that compiles to Javscript \cite{elm_lang}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{figs/architecture.png}
  \caption{Dataflow diagram of the tool}
  \label{fig:architecture}
\end{figure}


% \digraph{abc}{
%   rankdir=LR
%     
%   source [label = "âœsource",shape=MSquare, color="darkolivegreen4",style=filled]
% 
%   subgraph plugin {
%     style=filled;
%     color=lightgrey;
%     node [style=filled,color=gray,shape=box];
%     label = "plugin";
%     
%     ghc [label="ðŸ”¨GHC",color="darkorchid"]
%     plugin [color="brown1",label="ðŸ§©plugin"]
%     dump1 [label = "ðŸ“dump.zip"]
%     dump2 [label = "ðŸ“dumb.zip"]
%   
%     source -> ghc
%     plugin -> ghc [dir=both]
%     plugin -> dump1
%     dump1 -> dump2 [style=dotted]
%   
%     dump2 -> frontend
%   }
% 
%   subgraph frontend {
%     node [style=filled];
%     label = "frontend";
%     color=blue
%     frontend [color=lightblue,label="ðŸ•µfrontend"]
%   }
% }
% 
\section{Creating the GHC plugin}

By far the most logical and convenient method for obtaining all the available information in the AST it to capture
it directly using a GHC core2core plugin that intersperses each transformation with an identity transformation that
saves a JSON representation of the AST to a file as a side effect. 

\subsection{Capturing the information}

If we wish to support multiple recent versions of GHC we need to deal with the fact that the Core ADT has undergone
a few minor changes and additions. We believe that the solution is to create some auxiliary definition to which we can
map various versions of the Core ADT. This was done very efficiently by building upon the existing \mono{ghc-dump} package,
which already implemented such an ADT as well as a version agnostic conversion module with the help of \mono{min_version_GHC}
macro statements \cite{ghc_dump}. 

What \mono{ghc-dump} also intelligently addresses, is the issue of possible infinite recursion
in the Core AST through the \mono{CoreExpr} inside the unfolding of a \mono{CoreBndr}. If we demote each
call site to a simple identifier, we obtain a finite representation that we can later reconstruct by traversing
the AST with an environment.

\subsection{Globally unique variables}

It is not strictly necessary for variable names in a program to be unique. A variable name always
references the nearest binding site. This holds true for Core as well, but is not very convenient
when we want to analyze a certain variable in isolation. After all, naked variables are ambiguous without a given
environment. Consider the definition of tail:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
tail xs = case xs of
  x:xs -> xs
  _    -> error "tail of empty list"
\end{minted}
\end{listing}

We cannot simply refer to the variable \mono{xs} as that name has two different binding sites.
We solve this by running a \textit{uniqify} pass before each snapshot that freshens all duplicate uniques in the entire
module after each core2core transformation. This gives us the ability to refer to a binding site and its usages unambiguously using simply an integer.
The big idea here is that any viewing logic is completely decoupled from binding semantics:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
tail xs_0 = case xs_0 of
  x_1:xs_2 -> xs_2
  _        -> error "tail of empty list"
\end{minted}
\end{listing}

It is possible to omit the numbered suffixes when displaying the AST, but internally it is very useful to be able to make
this distinction without any further effort.

\subsection{Detecting changes}

If a module is of a slightly larger size, it becomes difficult to spot the changes made by a certain
transformation, if there even are any. To address this, we decided to develop a feature that allows for
the filtering of code that remains unchanged. Let us define what unchanged means in this context. It is
important to make the subtle distinction between syntactic equivalence and $\alpha$-equivalence. The difference
is that the latter is agnostic to the names of variables, as long as they refer to the same binding site.

We can quickly solve the decision problem of syntactic equality by calculating a hash of an expression beforehand
and simply checking for equality of this hash value. We considered using recent improvements of full sub expression
matching \cite{hashing_mod_alpha}, but decided against it as it was not clear how to effectively present the results
nor did it rarely prove useful to isolate changes in the AST as they were rarely local to begin with.
Instead, we opted for a far simpler approach where we only hash the toplevel functions, and provide a more crude
option to hide any toplevel definitions that have not changed at all.

All in all, we still recommend that issues are attempted to be reproduced in small modules as the amount of
noise can quickly become overwhelming despite change detection.

\section{Creating the frontend application}

\subsection{Reproducing the AST}
It would have been extremely tedious to have to constantly maintain a Core ADT in Elm along with a JSON
parser that is compatible with the JSON output of the Haskell plugin. Luckily, we were able to use the
\mono{haskell-to-elm} \cite{haskell_to_elm} package to automatically derive all the needed boilerplate code.

For example the \mono{Alt} datatype (i.e. an arm of a case expression) is defined as follows in Haskell:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
data Alt = Alt
    { altCon :: AltCon
    , altBinders :: [Binder]
    , altRHS :: Expr
    }
    deriving (Generic)
\end{minted}
\end{listing}

The corresponding, auto generated, Elm definition becomes:

\begin{listing}[H]
\begin{minted}[linenos]{elm}
type alias Alt =
    { altCon : AltCon
    , altBinders : List Binder
    , altRHS : Expr
    }

altDecoder : Json.Decode.Decoder Alt
altDecoder =
    Json.Decode.succeed Alt |>
    Json.Decode.Pipeline.required "altCon" altConDecoder |>
    Json.Decode.Pipeline.required "altBinders" (Json.Decode.list binderDecoder) |>
    Json.Decode.Pipeline.required "altRHS" exprDecoder
\end{minted}
\end{listing}

Conveniently, it would be very easy in the future to extend the Haskell ADT with additional information
because it is the single source of truth; The Elm ADT and JSON machinery can then be regenerated with a single command.

Additionally, we use this pipeline embellish the AST. Specifically, we add a field to each \mono{BinderId} of the type:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
type BinderThunk = Found Binder | NotFound | Untouched
\end{minted}
\end{listing}

Intially this field is set to the \mono{Untouched} variant. Once the finitely encoded AST is decoded into the 
Elm universe, a reconstruction traversal takes place that with the help of an environment strengthens the 
\mono{BinderThunk} with a reference to its binder. The \mono{NotFound} variant is pure for verification purposes
and should never occur in a sound input program. It is also important to note that Elm's single static assignment
semantics naturally implies that the \mono{Binder} is never copied, but only referenced.


\subsection{Pretty printing}

It certainly should be considered useful to display the Core in exactly the same way that
GHC does. After all, this is what programmers are currently already used to and its design
has been given a lot of thought. However, we felt a need to first create a separate representation
that is tailored to those who have not seen Core before.

Haskell programmers that care enough to inspect the interaction with the compiler are likely to be
avid readers of at least basic Haskell syntax. Therefore, we decided to create a pretty printer that attempts
to be as similar to Haskell source as possible. Just like GHC, we used pretty printing the method developed 
by Waddler \cite{prettier_printer}, implemented in Elm using \mono{elm-pretty-printer} \cite{prettier_printer_elm}.
We believe that such a representation is a suitable way to minimize the shock reaction that newcomers might have
when they first encounter Core.

To facilitate syntax hightlighting, the pretty printer adds the appropriate token identifiers such that 
\mono{pygments} \cite{pygments} can be used to colorize the output.

To compare, consider again the Core representation presented in \cref{section:background:ghc} with the quicksort
representation produced by our pretty printer:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
quicksort :: forall a. Ord a -> [a] -> [a]
quicksort a $dOrd ds = case ds of
  { : x xs -> GHC.Base.++ @a
                (quicksort @a $dOrd
                   (GHC.List.filter @a
                      (\ds -> GHC.Classes.< @a $dOrd ds x) xs))
                (GHC.Base.++ @a
                   (GHC.Base.build @a
                      (\a c n -> c x n))
                   (quicksort @a $dOrd
                      (GHC.List.filter @a
                         (\ds -> GHC.Classes.> @a $dOrd ds x) xs)))
    [] -> GHC.Types.[] @a
  }
\end{minted}
\end{listing}

Notice that although this might look like normal Haskell, it contains explicit type variables like
\mono{a}, hinting at the SystemFC nature of Core.

\subsection{Including the source}
It goes without saying that the source code of a module is an essential part of any analysis. Therefore,
the plugin copies the source code and runs it through the \mono{pygmentize} \cite{pygments} tool to obtain
an HTML representation of the source code that is highlighted exactly the same way as the pretty printed Core.
This HTML source code is embedded in the output of the dump.

The artificacts produced by a single module now look like this:

\begin{listing}[H]
\begin{minted}[linenos]{text}
Quicksort_0.json
Quicksort_10.json
Quicksort_11.json
Quicksort_12.json
Quicksort_13.json
Quicksort_14.json
Quicksort_15.json
Quicksort_16.json
Quicksort_17.json
Quicksort_18.json
Quicksort_1.json
Quicksort_2.json
Quicksort_3.json
Quicksort_4.json
Quicksort_5.json
Quicksort_6.json
Quicksort_7.json
Quicksort_8.json
Quicksort_9.json
Quicksort.hs
Quicksort.html
Quicksort_meta.json
\end{minted}
\end{listing}

All these files will be compressed in a zip archive to keep the size of the output smaller. It also makes for
a convenient atomic entity to load up in the frontend application where it is unzipped on the fly.

\subsection{Unfoldings and capture sizes}

The entire body of a variable is sometimes saved as part of its \mono{IdInfo} which is exported to interface
files such that inlining can take place across modules. This part of the \mono{IdInfo} struct is called the
\textit{unfolding} of a variable. By nature, this can be a very large expression. At this time, we have no
need for the exact unfolding in the frontend application, other than knowing it exists. Therefore, we decided 
to replace any unfolding with a string literal to indicate that the unfolding was removed:

\begin{listing}[H]
\begin{minted}[linenos]{haskell}
removeUnfolding :: Unfolding -> Unfolding
removeUnfolding u@CoreUnfolding {..} = 
  u { unfTemplate = ELit (MachStr (T.pack "unfolding removed by plugin")) }
removeUnfolding x = x
\end{minted}
\end{listing}

This reduces the size of captures in some cases by a factor of 2.

\subsection{Interactions}

Asside from a more human readible representation and syntax highlighting, the user is further supported by
a number of interactive features. These include:

\begin{itemize}
  \item Highlighting binding and call sites of a variable on hover
  \item Renaming variables
  \item Toggling various Core display options such as hiding typelevel terms and type applications, desugaring
        leading lambda abstractions, etc.
  \item Multiple approaches to hiding toplevel bindings such as hiding all but the selected binding, which
        can conveniently be followed up by un-hiding its referenced bindings transitively.
  \item A variable detail popup that shows all the available information of a variable.
  \item Querying variables and their types on Hoogle.
\end{itemize}

\subsection{Improving performance with cache semantics}

The way that Elm operates --- like many other interactive browser based applications --- is by rendering the HTML on every
update and then diffing the result with the current state of the DOM to create a minimal change list. This is generally a very
good strategy because mutating the DOM is by far the most dominant cost contributor. However, when it comes to pretty printing a
large Core expression the \mono{view} function starts to incur a significant cost. This is wasteful because many updates do not
actually affect the output of the pretty printer (events like \mono{onHover} and \mono{onClick} for example).
Initially this led to some serious usability issues where the application would stutter and freeze.

We were able to overcome this problem using the \mono{Html.Lazy} module, which takes some HTML producing closure and its arguments
separately. If on some update the arguments have not changed, the closure is not evaluated and a cached result is returned. Regardless,
the aforementioned diffing still takes place, reducing the cost of the update to negligible. Of course, we cannot get around the fact that
any updates that do affect the output of the pretty printer might still cause some stutters, but the frequency of such updates is 
generally far lower.

\subsection{Note on deployment}

By virtue of being solely a stateless HTML + JavaScript application after compilation, means that the frontend can
easily and cheaply be deployed to any static file hosting service. Because the dump files are never send to the server,
we can discard any privacy concerns while still providing a no effort method to analyze the dumps. Anyone is still free
of course, to build and host their own build of the frontend which is similarly open sourced.

